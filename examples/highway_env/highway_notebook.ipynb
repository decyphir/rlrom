{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  train_highway_env import *\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import show\n",
    "import rlrom.plots\n",
    "from rlrom.testers import RLTester\n",
    "from pprint import pprint\n",
    "output_notebook()  # Add this at the top of your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = utils.load_cfg('cfg_main.yml')\n",
    "tester = RLTester(cfg)\n",
    "episodes = []\n",
    "num_ep = 2\n",
    "\n",
    "res = dict()\n",
    "res_rew_f_list = []\n",
    "res_eval_f_list = []\n",
    "\n",
    "for i in range(0,num_ep):\n",
    "    tester.run_seed(seed=i, num_steps=100)\n",
    "    episodes.append(tester.env.episode)\n",
    "    res, res_all_ep, res_rew_f_list, res_eval_f_list = tester.env.eval_episode(res=res, res_rew_f_list=res_rew_f_list,res_eval_f_list=res_eval_f_list )\n",
    "\n",
    "print(), print(), print()\n",
    "pprint(res_all_ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res['rewards'])\n",
    "#pprint(res_all_ep)\n",
    "print(res_rew_f_list)\n",
    "#pprint(res_eval_f_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(res_all_ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = utils.load_cfg('cfg_main.yml')    \n",
    "tester = RLTester(cfg, render_mode=None)\n",
    "tester.init_env()\n",
    "res = dict()\n",
    "for i in range(0,num_ep):\n",
    "    res, res_all_ep, res_rew_f_list, res_eval_f_list  = tester.env.eval_episode(episode=episodes[i],res=res)\n",
    "\n",
    "pprint(res_rew_f_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lay = \"\"\"                        \n",
    "    ego_y\n",
    "    ev_right_lane\n",
    "    reward\n",
    "    \"\"\"\n",
    "fig, status=  rlrom.plots.get_fig(tester.env, lay)\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = utils.load_cfg('cfg_main.yml')    \n",
    "cfg_specs = cfg['cfg_specs']\n",
    "pprint(cfg_specs['obs_formulas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff=  cfg_specs['reward'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = dict()\n",
    "nn1 = 'f1'\n",
    "nn2 = 'f2'\n",
    "dd[nn1] = 1\n",
    "dd[nn2] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na, va = next(iter(dd.items()))\n",
    "print(na, va)\n",
    "na, va = next(iter(dd.items()))\n",
    "print(na, va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = iter(dd.items())\n",
    "na, va = next(ii)\n",
    "print(na, va)\n",
    "na, va = next(ii)\n",
    "print(na, va)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
